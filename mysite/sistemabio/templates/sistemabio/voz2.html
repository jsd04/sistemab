
{% extends "sistemabio/base.html" %}
{% load static %}
{% block content %}
 

<header class="row" style="position: relative; height: 50vh; width: 100%;">
  <div class="col s12 m11 l9 xl8 " style="position: absolute; top: 0px; height: 60%; left: 0px;">
    <img alt="imagen1" src="{% static 'sistemabio/img/rec4.png' %}" class="responsive-image"
      style="height: 200%; width: 80%; left: 0px; top: 0px; position: absolute; object-fit: cover;" />
  </div>
  <div class="col s12 m9 l9 xl8 white-text"
    style="position: absolute; top: 50%; left: 30%; height: 100%; transform: translate(-50%, -50%); width: 50%;">
    <br>
    <br>
    <blockquote>

      <h2 class="subtitulo black-text ">
        <b>
          VOZ <br />
        </b>
      </h2>
    </blockquote>
  </div>

  <div class="col m6 l6 xl5 hide-on-small-only" style="height: 100%; position: absolute; top: 0%; right: 0%;">
    <img alt="" src="{% static 'sistemabio/img/parteba9.png' %}" class="responsive-img"
      style="position: absolute; right: -5px; top: 0px; height: 100%; width: 50%;">
  </div>
</header>
<br />
<br />
<br />

<!-- <div class="col-md-8 mx-auto">
  <div class="card">
    <div class="card-header bg-success text-center" style="--bs-bg-opacity: .7;">
      <h3 class="text-white">Captura la voz
        <i class="material-icons small rounded-circle " style="font-size:40px;">mic
        </i>
      </h3>
    </div>
    <div class="card-body text-left bg-success " style="--bs-bg-opacity: .3;"> -->
      <!-- <form  method="POST" enctype="multipart/form-data" >
        {% csrf_token %}  -->

        <!-- <div class="container">
          <div class="row">
            <div class="col ">

              <p class="text-black" style="font-family: 'Franklin Gothic Medium'; font-size: 20px;">
                <b>Aquí se realiza la captura de voz</b>
              </p>
              <br>
              <p>
                Al oprimir el boton de "Record" dirás la siguiente frase:
                "Acceso al edificio RS"
              </p>
              <label for="id_usuario">Usuario:</label>
              <select class="form-control" type="text" id="id_usuario" name="id_usuario" >
                <option value="{{inquilino.id_usuario}}" selected="selected">Id {{inquilino.id_usuario}} -> {{inquilino.id_usuario}} {{inquilino.nombre}} {{inquilino.ap_paterno}} {{inquilino.ap_materno}}</option>
              </select readonly>
              
              <label for="id_tipo_sesion">Tipo de sesion:</label>
              <select class="form-control" type="text" id="id_tipo_sesion" name="id_tipo_sesion" >
                <option value="2" selected="selected">Tipo sesion {{sesion.id_tipo_sesion}} ->VOZ</option>
              </select readonly>

              <label for="id_dato">Dato:</label>
              <input type="text" name="dato" class="form-control" id="id_dato"/> 
              
              <h5></h5> -->
              <!-- {{form}} -->
            <!-- </div>
            <div class="row justify-content-center">
              <div class="col-4 aling-self-center">
                <button type="button " class="btn btn-warning " id="record">Record</button>
              </div>
            </div>
            <br>
            <br>
            <br>
            <div class="col-6 aling-self-center">
              <div id="sound-clip"></div>
            </div>
            <script src="{% static 'sistemabio/biometricos/voiceMemo.js' %}"></script> -->
            <!-- <img  src="{% static 'sistemabio/img/rec4.png' %}" class="responsive-image"> -->
          <!-- </div>
            <br>
                 -->

          <!-- ******EL BOTON DE ACEPTAR SOLO REGRESA ******* -->
          <!-- <div class="row justify-content-end">
            <div class="col-4 align-self-end">
              <a class="waves-effect waves-light text-white btn p-2 text-center  "
                style="background: rgb(29, 240, 134);border-radius: 20px;" href="javascript:window.history.back(); ">
                Aceptar
                <i class="material-icons small rounded-circle " style="font-size:20px;">mic
                </i>
              </a>
            </div>
          </div> -->
          <!-- <br>
          <button class="btn btn-info w-100" type="submit">
            Guardar 
            <i class="material-icons "> save</i>
          </button>
        </div> -->
      <!-- </form> -->

    <!-- </div>
  </div>
</div> -->
<br>

<!-- <div class="app">
  <select name="" id="micSelect">
    <option value="default">Predeterminado - Micrófono (Realtek High Definition Audio)</option>
    <option value="communications">Comunicaciones - Micrófono (Realtek High Definition Audio)</option>
    <option value="fc70d5f1664e2b0047aa4c1bc20c3fc5b774295ec0e1b2d8ecb5f5918832771e">
      Micrófono (Realtek High Definition Audio)</option>
    <option value="e0cd06f3ec3ffc7a879f2aa2c5e5f42270a9abf9869ceefdf0a822282953829b">
      Mezcla estéreo (Realtek High Definition Audio)</option>
  </select>

 

  <a id="download" href="blob:https://cdpn.io/d5919a41-ddd3-46c8-ac53-4cf483aa4afe" download="output.wav">Descargar</a>

  <div class="audio-controls">
    <button id="record">Grabar</button>
    <button id="stop">Stop</button>
    <audio id="audio" controls="" src="blob:https://cdpn.io/d5919a41-ddd3-46c8-ac53-4cf483aa4afe"></audio>
  </div>

  <div id="msg" style="visibility: hidden;">Grabando...</div>
  <canvas width="500" height="300"></canvas>

  <div>
  
    <script id="rendered-js">
(async () => {
  let leftchannel = [];
  let rightchannel = [];
  let recorder = null;
  let recording = false;
  let recordingLength = 0;
  let volume = null;
  let audioInput = null;
  let sampleRate = null;
  let AudioContext = window.AudioContext || window.webkitAudioContext;
  let context = null;
  let analyser = null;
  let canvas = document.querySelector('canvas');
  let canvasCtx = canvas.getContext("2d");
  let visualSelect = document.querySelector('#visSelect');
  let micSelect = document.querySelector('#micSelect');
  let stream = null;
  let tested = false;

  try {
    window.stream = stream = await getStream();
    console.log('Got stream');
  } catch (err) {
    alert('Issue getting mic', err);
  }

  const deviceInfos = await navigator.mediaDevices.enumerateDevices();

  var mics = [];
  for (let i = 0; i !== deviceInfos.length; ++i) {
    let deviceInfo = deviceInfos[i];
    if (deviceInfo.kind === 'audioinput') {
      mics.push(deviceInfo);
      let label = deviceInfo.label ||
      'Microphone ' + mics.length;
      console.log('Mic ', label + ' ' + deviceInfo.deviceId);
      const option = document.createElement('option');
      option.value = deviceInfo.deviceId;
      option.text = label;
      micSelect.appendChild(option);
    }
  }

  function getStream(constraints) {
    if (!constraints) {
      constraints = { audio: true, video: false };
    }
    return navigator.mediaDevices.getUserMedia(constraints);
  }


  setUpRecording();

  function setUpRecording() {
    context = new AudioContext();
    sampleRate = context.sampleRate;

    // crea un nodo de ganancia
    volume = context.createGain();

    // crea un nodo de audio desde el flujo entrante del micrófono
    audioInput = context.createMediaStreamSource(stream);

    // Crear analizador
    analyser = context.createAnalyser();

    // conectar la entrada de audio al analizador
    audioInput.connect(analyser);

    // conectar analizador al control de volumen
    // analyser.connect(volume);

    let bufferSize = 2048;
    let recorder = context.createScriptProcessor(bufferSize, 2, 2);

    // conectamos el control de volumen al procesador
    // volume.connect(recorder);

    analyser.connect(recorder);

    // finally connect the processor to the output
    recorder.connect(context.destination);

    recorder.onaudioprocess = function (e) {
      // Check 
      if (!recording) return;
      // Haz algo con los datos, es decir, convierte esto a WAV
      console.log('recording');
      let left = e.inputBuffer.getChannelData(0);
      let right = e.inputBuffer.getChannelData(1);
      if (!tested) {
        tested = true;
        // si esto se reduce a 0 no estamos recibiendo ningún sonido
        if (!left.reduce((a, b) => a + b)) {
          alert("There seems to be an issue with your Mic");
          // clean up;
          stop();
          stream.getTracks().forEach(function (track) {
            track.stop();
          });
          context.close();
        }
      }
      // clonamos las muestras
      leftchannel.push(new Float32Array(left));
      rightchannel.push(new Float32Array(right));
      recordingLength += bufferSize;
    };
    visualize();
  };



  function mergeBuffers(channelBuffer, recordingLength) {
    let result = new Float32Array(recordingLength);
    let offset = 0;
    let lng = channelBuffer.length;
    for (let i = 0; i < lng; i++) {
      let buffer = channelBuffer[i];
      result.set(buffer, offset);
      offset += buffer.length;
    }
    return result;
  }

  function interleave(leftChannel, rightChannel) {
    let length = leftChannel.length + rightChannel.length;
    let result = new Float32Array(length);

    let inputIndex = 0;

    for (let index = 0; index < length;) {
      result[index++] = leftChannel[inputIndex];
      result[index++] = rightChannel[inputIndex];
      inputIndex++;
    }
    return result;
  }

  function writeUTFBytes(view, offset, string) {
    let lng = string.length;
    for (let i = 0; i < lng; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  }

  function start() {
    recording = true;
    document.querySelector('#msg').style.visibility = 'visible';
    // reset the buffers for the new recording
    leftchannel.length = rightchannel.length = 0;
    recordingLength = 0;
    console.log('context: ', !!context);
    if (!context) setUpRecording();
  }

  function stop() {
    console.log('Stop');
    recording = false;
    document.querySelector('#msg').style.visibility = 'hidden';


    // bajamos los canales izquierdo y derecho
    let leftBuffer = mergeBuffers(leftchannel, recordingLength);
    let rightBuffer = mergeBuffers(rightchannel, recordingLength);
    // we interleave both channels together
    let interleaved = interleave(leftBuffer, rightBuffer);

    ///////////// WAV Encode /////////////////
    // from http://typedarray.org/from-microphone-to-wav-with-getusermedia-and-web-audio/
    //

    // creamos nuestro archivo wav
    let buffer = new ArrayBuffer(44 + interleaved.length * 2);
    let view = new DataView(buffer);

    // RIFF chunk descriptor
    writeUTFBytes(view, 0, 'RIFF');
    view.setUint32(4, 44 + interleaved.length * 2, true);
    writeUTFBytes(view, 8, 'WAVE');
    // FMT sub-chunk
    writeUTFBytes(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    // stereo (2 channels)
    view.setUint16(22, 2, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 4, true);
    view.setUint16(32, 4, true);
    view.setUint16(34, 16, true);
    // data sub-chunk
    writeUTFBytes(view, 36, 'data');
    view.setUint32(40, interleaved.length * 2, true);

    // escribe las muestras de PCM
    let lng = interleaved.length;
    let index = 44;
    let volume = 1;
    for (let i = 0; i < lng; i++) {
      view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
      index += 2;
    }

    // our final binary blob
    const blob = new Blob([view], { type: 'audio/wav' });

    const audioUrl = URL.createObjectURL(blob);
    console.log('BLOB ', blob);
    console.log('URL ', audioUrl);
    document.querySelector('#audio').setAttribute('src', audioUrl);
    const link = document.querySelector('#download');
    link.setAttribute('href', audioUrl);
    link.download = 'output.wav';
  }

  // Visualizer function from
  // https://webaudiodemos.appspot.com/AudioRecorder/index.html
  //
  function visualize() {
    WIDTH = canvas.width;
    HEIGHT = canvas.height;
    CENTERX = canvas.width / 2;
    CENTERY = canvas.height / 2;

    let visualSetting = visualSelect.value;
    console.log(visualSetting);
    if (!analyser) return;

    if (visualSetting === "sinewave") {
      analyser.fftSize = 2048;
      var bufferLength = analyser.fftSize;
      console.log(bufferLength);
      var dataArray = new Uint8Array(bufferLength);

      canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

      var draw = function () {

        drawVisual = requestAnimationFrame(draw);

        analyser.getByteTimeDomainData(dataArray);

        canvasCtx.fillStyle = 'rgb(200, 200, 200)';
        canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

        canvasCtx.lineWidth = 2;
        canvasCtx.strokeStyle = 'rgb(0, 0, 0)';

        canvasCtx.beginPath();

        var sliceWidth = WIDTH * 1.0 / bufferLength;
        var x = 0;

        for (var i = 0; i < bufferLength; i++) {

          var v = dataArray[i] / 128.0;
          var y = v * HEIGHT / 2;

          if (i === 0) {
            canvasCtx.moveTo(x, y);
          } else {
            canvasCtx.lineTo(x, y);
          }

          x += sliceWidth;
        }

        canvasCtx.lineTo(canvas.width, canvas.height / 2);
        canvasCtx.stroke();
      };

      draw();

    } else if (visualSetting == "frequencybars") {
      analyser.fftSize = 64;
      var bufferLengthAlt = analyser.frequencyBinCount;
      console.log(bufferLengthAlt);
      var dataArrayAlt = new Uint8Array(bufferLengthAlt);

      canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

      var drawAlt = function () {
        drawVisual = requestAnimationFrame(drawAlt);

        analyser.getByteFrequencyData(dataArrayAlt);

        canvasCtx.fillStyle = 'rgb(0, 0, 0)';
        canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

        var barWidth = WIDTH / bufferLengthAlt;
        var barHeight;
        var x = 0;

        for (var i = 0; i < bufferLengthAlt; i++) {
          barHeight = dataArrayAlt[i];

          canvasCtx.fillStyle = 'rgb(' + (barHeight + 100) + ',50,50)';
          canvasCtx.fillRect(x, HEIGHT - barHeight / 2, barWidth, barHeight / 2);

          x += barWidth + 1;
        }
      };

      drawAlt();

    } else if (visualSetting == "circle") {
      analyser.fftSize = 32;
      let bufferLength = analyser.frequencyBinCount;
      console.log(bufferLength);
      let dataArray = new Uint8Array(bufferLength);

      canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

      let draw = () => {
        drawVisual = requestAnimationFrame(draw);

        analyser.getByteFrequencyData(dataArray);
        canvasCtx.fillStyle = 'rgb(0, 0, 0)';
        canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

        // let radius = dataArray.reduce((a,b) => a + b) / bufferLength;
        let radius = dataArray[2] / 2;
        if (radius < 20) radius = 20;
        if (radius > 100) radius = 100;
        // console.log('Radius ', radius)
        canvasCtx.beginPath();
        canvasCtx.arc(CENTERX, CENTERY, radius, 0, 2 * Math.PI, false);
        // canvasCtx.fillStyle = 'rgb(50,50,' + (radius+100) +')';
        // canvasCtx.fill();
        canvasCtx.lineWidth = 6;
        canvasCtx.strokeStyle = 'rgb(50,50,' + (radius + 100) + ')';
        canvasCtx.stroke();
      };
      draw();
    }

  }

  visualSelect.onchange = function () {
    window.cancelAnimationFrame(drawVisual);
    visualize();
  };

  micSelect.onchange = async e => {
    console.log('now use device ', micSelect.value);
    stream.getTracks().forEach(function (track) {
      track.stop();
    });
    context.close();

    stream = await getStream({ audio: {
        deviceId: { exact: micSelect.value } }, video: false });
    setUpRecording();
  };

  function pause() {
    recording = false;
    context.suspend();
  }

  function resume() {
    recording = true;
    context.resume();
  }

  document.querySelector('#record').onclick = e => {
    console.log('Start recording');
    start();
  };

  document.querySelector('#stop').onclick = e => {
    stop();
  };
})();
//# sourceURL=pen.js
    </script>

  



  </div>
</div> -->

<br>
<div class="output-container">
  <div class="output-sizer">
  <!-- <div id="result_div" class="result">-->
  <!-- <iframe id="result" name="CodePen" title="CodePen Preview" src="https://cdpn.io/liontv/fullpage/QJpJJv?anon=true&amp;view=" sandbox="allow-forms allow-modals allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-top-navigation-by-user-activation allow-downloads allow-presentation" allow="accelerometer; camera; encrypted-media; display-capture; geolocation; gyroscope; microphone; midi; clipboard-read; clipboard-write; web-share" scrolling="auto" allowtransparency="true" allowpaymentrequest="true" allowfullscreen="true" class="result-iframe " loading="lazy">
            </iframe> 
  <div id="editor-drag-cover" class="drag-cover" style="display: none;"></div>
  </div> -->
  <!-- <html lang="en"><head>
    <script>
    window.console = window.console || function(t) {};
  </script>
  </head>
  -->
  <!-- <body translate="no"> -->
    <div class="app">
    <select name="" id="micSelect">
      <option value="default">Predeterminado - Micrófono (Realtek High Definition Audio)</option>
      <option value="communications">Comunicaciones - Micrófono (Realtek High Definition Audio)</option>
      <option value="fc70d5f1664e2b0047aa4c1bc20c3fc5b774295ec0e1b2d8ecb5f5918832771e">
        Micrófono (Realtek High Definition Audio)</option>
        <option value="e0cd06f3ec3ffc7a879f2aa2c5e5f42270a9abf9869ceefdf0a822282953829b">Mezcla estéreo (Realtek High Definition Audio)</option></select>
  
    <select id="visSelect">
      <option value="frequencybars">Bar</option>
      <option value="sinewave">Wave</option>
      <option value="circle">Circle</option>
    </select>
  
    <a id="download" href="blob:https://cdpn.io/d5919a41-ddd3-46c8-ac53-4cf483aa4afe" download="output.wav">Descargar</a>
  
    <div class="audio-controls">
      <button id="record">Grabar</button>
      <button id="stop">Stop</button>
      <audio id="audio" controls="" src="blob:https://cdpn.io/d5919a41-ddd3-46c8-ac53-4cf483aa4afe"></audio>
    </div>
  
    <div id="msg" style="visibility: hidden;">Grabando...</div>
    <canvas width="500" height="300"></canvas>
  <div>
    
        <script id="rendered-js">
  (async () => {
    let leftchannel = [];
    let rightchannel = [];
    let recorder = null;
    let recording = false;
    let recordingLength = 0;
    let volume = null;
    let audioInput = null;
    let sampleRate = null;
    let AudioContext = window.AudioContext || window.webkitAudioContext;
    let context = null;
    let analyser = null;
    let canvas = document.querySelector('canvas');
    let canvasCtx = canvas.getContext("2d");
    let visualSelect = document.querySelector('#visSelect');
    let micSelect = document.querySelector('#micSelect');
    let stream = null;
    let tested = false;
  
    try {
      window.stream = stream = await getStream();
      console.log('Got stream');
    } catch (err) {
      alert('Issue getting mic', err);
    }
  
    const deviceInfos = await navigator.mediaDevices.enumerateDevices();
  
    var mics = [];
    for (let i = 0; i !== deviceInfos.length; ++i) {
      let deviceInfo = deviceInfos[i];
      if (deviceInfo.kind === 'audioinput') {
        mics.push(deviceInfo);
        let label = deviceInfo.label ||
        'Microphone ' + mics.length;
        console.log('Mic ', label + ' ' + deviceInfo.deviceId);
        const option = document.createElement('option');
        option.value = deviceInfo.deviceId;
        option.text = label;
        micSelect.appendChild(option);
      }
    }
  
    function getStream(constraints) {
      if (!constraints) {
        constraints = { audio: true, video: false };
      }
      return navigator.mediaDevices.getUserMedia(constraints);
    }
  
  
    setUpRecording();
  
    function setUpRecording() {
      context = new AudioContext();
      sampleRate = context.sampleRate;
  
      // crea un nodo de ganancia
      volume = context.createGain();
  
      // crea un nodo de audio desde el flujo entrante del micrófono
      audioInput = context.createMediaStreamSource(stream);
  
      // Crear analizador
      analyser = context.createAnalyser();
  
      // conectar la entrada de audio al analizador
      audioInput.connect(analyser);
  
      // conectar analizador al control de volumen
      // analyser.connect(volume);
  
      let bufferSize = 2048;
      let recorder = context.createScriptProcessor(bufferSize, 2, 2);
  
      // conectamos el control de volumen al procesador
      // volume.connect(recorder);
  
      analyser.connect(recorder);
  
      // finally connect the processor to the output
      recorder.connect(context.destination);
  
      recorder.onaudioprocess = function (e) {
        // Check 
        if (!recording) return;
        // Haz algo con los datos, es decir, convierte esto a WAV
        console.log('recording');
        let left = e.inputBuffer.getChannelData(0);
        let right = e.inputBuffer.getChannelData(1);
        if (!tested) {
          tested = true;
          // si esto se reduce a 0 no estamos recibiendo ningún sonido
          if (!left.reduce((a, b) => a + b)) {
            alert("There seems to be an issue with your Mic");
            // clean up;
            stop();
            stream.getTracks().forEach(function (track) {
              track.stop();
            });
            context.close();
          }
        }
        // clonamos las muestras
        leftchannel.push(new Float32Array(left));
        rightchannel.push(new Float32Array(right));
        recordingLength += bufferSize;
      };
      visualize();
    };
  
  
  
    function mergeBuffers(channelBuffer, recordingLength) {
      let result = new Float32Array(recordingLength);
      let offset = 0;
      let lng = channelBuffer.length;
      for (let i = 0; i < lng; i++) {
        let buffer = channelBuffer[i];
        result.set(buffer, offset);
        offset += buffer.length;
      }
      return result;
    }
  
    function interleave(leftChannel, rightChannel) {
      let length = leftChannel.length + rightChannel.length;
      let result = new Float32Array(length);
  
      let inputIndex = 0;
  
      for (let index = 0; index < length;) {
        result[index++] = leftChannel[inputIndex];
        result[index++] = rightChannel[inputIndex];
        inputIndex++;
      }
      return result;
    }
  
    function writeUTFBytes(view, offset, string) {
      let lng = string.length;
      for (let i = 0; i < lng; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }
  
    function start() {
      recording = true;
      document.querySelector('#msg').style.visibility = 'visible';
      // reset the buffers for the new recording
      leftchannel.length = rightchannel.length = 0;
      recordingLength = 0;
      console.log('context: ', !!context);
      if (!context) setUpRecording();
    }
  
    function stop() {
      console.log('Stop');
      recording = false;
      document.querySelector('#msg').style.visibility = 'hidden';
  
  
      // bajamos los canales izquierdo y derecho
      let leftBuffer = mergeBuffers(leftchannel, recordingLength);
      let rightBuffer = mergeBuffers(rightchannel, recordingLength);
      // we interleave both channels together
      let interleaved = interleave(leftBuffer, rightBuffer);
  
      ///////////// WAV Encode /////////////////
      // from http://typedarray.org/from-microphone-to-wav-with-getusermedia-and-web-audio/
      //
  
      // creamos nuestro archivo wav
      let buffer = new ArrayBuffer(44 + interleaved.length * 2);
      let view = new DataView(buffer);
  
      // RIFF chunk descriptor
      writeUTFBytes(view, 0, 'RIFF');
      view.setUint32(4, 44 + interleaved.length * 2, true);
      writeUTFBytes(view, 8, 'WAVE');
      // FMT sub-chunk
      writeUTFBytes(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      // stereo (2 channels)
      view.setUint16(22, 2, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 4, true);
      view.setUint16(32, 4, true);
      view.setUint16(34, 16, true);
      // data sub-chunk
      writeUTFBytes(view, 36, 'data');
      view.setUint32(40, interleaved.length * 2, true);
  
      // escribe las muestras de PCM
      let lng = interleaved.length;
      let index = 44;
      let volume = 1;
      for (let i = 0; i < lng; i++) {
        view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
        index += 2;
      }
  
      // our final binary blob
      const blob = new Blob([view], { type: 'audio/wav' });
  
      const audioUrl = URL.createObjectURL(blob);
      console.log('BLOB ', blob);
      console.log('URL ', audioUrl);
      document.querySelector('#audio').setAttribute('src', audioUrl);
      const link = document.querySelector('#download');
      link.setAttribute('href', audioUrl);
      link.download = 'output.wav';
    }
  
    // Visualizer function from
    // https://webaudiodemos.appspot.com/AudioRecorder/index.html
    //
    function visualize() {
      WIDTH = canvas.width;
      HEIGHT = canvas.height;
      CENTERX = canvas.width / 2;
      CENTERY = canvas.height / 2;
  
      let visualSetting = visualSelect.value;
      console.log(visualSetting);
      if (!analyser) return;
  
      if (visualSetting === "sinewave") {
        analyser.fftSize = 2048;
        var bufferLength = analyser.fftSize;
        console.log(bufferLength);
        var dataArray = new Uint8Array(bufferLength);
  
        canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);
  
        var draw = function () {
  
          drawVisual = requestAnimationFrame(draw);
  
          analyser.getByteTimeDomainData(dataArray);
  
          canvasCtx.fillStyle = 'rgb(200, 200, 200)';
          canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);
  
          canvasCtx.lineWidth = 2;
          canvasCtx.strokeStyle = 'rgb(0, 0, 0)';
  
          canvasCtx.beginPath();
  
          var sliceWidth = WIDTH * 1.0 / bufferLength;
          var x = 0;
  
          for (var i = 0; i < bufferLength; i++) {
  
            var v = dataArray[i] / 128.0;
            var y = v * HEIGHT / 2;
  
            if (i === 0) {
              canvasCtx.moveTo(x, y);
            } else {
              canvasCtx.lineTo(x, y);
            }
  
            x += sliceWidth;
          }
  
          canvasCtx.lineTo(canvas.width, canvas.height / 2);
          canvasCtx.stroke();
        };
  
        draw();
  
      } else if (visualSetting == "frequencybars") {
        analyser.fftSize = 64;
        var bufferLengthAlt = analyser.frequencyBinCount;
        console.log(bufferLengthAlt);
        var dataArrayAlt = new Uint8Array(bufferLengthAlt);
  
        canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);
  
        var drawAlt = function () {
          drawVisual = requestAnimationFrame(drawAlt);
  
          analyser.getByteFrequencyData(dataArrayAlt);
  
          canvasCtx.fillStyle = 'rgb(0, 0, 0)';
          canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);
  
          var barWidth = WIDTH / bufferLengthAlt;
          var barHeight;
          var x = 0;
  
          for (var i = 0; i < bufferLengthAlt; i++) {
            barHeight = dataArrayAlt[i];
  
            canvasCtx.fillStyle = 'rgb(' + (barHeight + 100) + ',50,50)';
            canvasCtx.fillRect(x, HEIGHT - barHeight / 2, barWidth, barHeight / 2);
  
            x += barWidth + 1;
          }
        };
  
        drawAlt();
  
      } else if (visualSetting == "circle") {
        analyser.fftSize = 32;
        let bufferLength = analyser.frequencyBinCount;
        console.log(bufferLength);
        let dataArray = new Uint8Array(bufferLength);
  
        canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);
  
        let draw = () => {
          drawVisual = requestAnimationFrame(draw);
  
          analyser.getByteFrequencyData(dataArray);
          canvasCtx.fillStyle = 'rgb(0, 0, 0)';
          canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);
  
          // let radius = dataArray.reduce((a,b) => a + b) / bufferLength;
          let radius = dataArray[2] / 2;
          if (radius < 20) radius = 20;
          if (radius > 100) radius = 100;
          // console.log('Radius ', radius)
          canvasCtx.beginPath();
          canvasCtx.arc(CENTERX, CENTERY, radius, 0, 2 * Math.PI, false);
          // canvasCtx.fillStyle = 'rgb(50,50,' + (radius+100) +')';
          // canvasCtx.fill();
          canvasCtx.lineWidth = 6;
          canvasCtx.strokeStyle = 'rgb(50,50,' + (radius + 100) + ')';
          canvasCtx.stroke();
        };
        draw();
      }
  
    }
  
    visualSelect.onchange = function () {
      window.cancelAnimationFrame(drawVisual);
      visualize();
    };
  
    micSelect.onchange = async e => {
      console.log('now use device ', micSelect.value);
      stream.getTracks().forEach(function (track) {
        track.stop();
      });
      context.close();
  
      stream = await getStream({ audio: {
          deviceId: { exact: micSelect.value } }, video: false });
      setUpRecording();
    };
  
    function pause() {
      recording = false;
      context.suspend();
    }
  
    function resume() {
      recording = true;
      context.resume();
    }
  
    document.querySelector('#record').onclick = e => {
      console.log('Start recording');
      start();
    };
  
    document.querySelector('#stop').onclick = e => {
      stop();
    };
  })();
  //# sourceURL=pen.js
      </script>
  
    
  
  
  
  </div></div>
<!-- </body> 
</html>-->
  </div>
  </div>

<br>
{% endblock %}